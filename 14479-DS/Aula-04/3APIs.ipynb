{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<div style=\"border: 1px solid black\">\n",
    "<b><center><font size=\"4\">Text2Analytics</font></center></b>\n",
    "\n",
    "<b><center><font size=\"3\">Data Acquisition</font></center></b>\n",
    "\n",
    "<b><center><font size=\"2\">3 - APIs</font></center></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook Developed by**: [Ricardo Campos](https://www.di.ubi.pt/~rcampos)<br>\n",
    "**email:**  ricardo.campos@ubi.pt<br>\n",
    "**Affiliation:** *Assistant Professor* @ [University of Beira Interior](http://www.ubi.pt);\n",
    "*Researcher* @ [LIAAD](https://www.inesctec.pt/en/centres/liaad)-[INESC TEC](https://www.inesctec.pt/en)\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p><a href=\"3APIs.ipynb\" title=\"Download Notebook\" download><img src=\"https://www.di.ubi.pt/~rcampos/assets/img_tutorials/download.jpg\" align = \"left\"  width=\"50\" height=\"50\" alt=\"Download Notebook\"></a></p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#APIs\" data-toc-modified-id=\"APIs-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>APIs</a></span><ul class=\"toc-item\"><li><span><a href=\"#New-York-Times\" data-toc-modified-id=\"New-York-Times-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>New York Times</a></span></li><li><span><a href=\"#NIF.PT\" data-toc-modified-id=\"NIF.PT-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>NIF.PT</a></span></li><li><span><a href=\"#Arquivo.pt-Images-Search\" data-toc-modified-id=\"Arquivo.pt-Images-Search-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Arquivo.pt Images Search</a></span></li><li><span><a href=\"#Wikipedia\" data-toc-modified-id=\"Wikipedia-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Wikipedia</a></span></li></ul></li><li><span><a href=\"#Other-APIs\" data-toc-modified-id=\"Other-APIs-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Other APIs</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 20px\">\n",
    "\n",
    "## Objetivos de aprendizagem  <a class=\"tocSkip\">\n",
    "    \n",
    "No final deste notebook o aluno deverá saber recorrer à utilização de APIs para proceder à aquisição de dados.\n",
    "\n",
    "\n",
    "## Learning Objectives  <a class=\"tocSkip\">\n",
    "       \n",
    "When concluding this notebook, the student should know how to use APIs to acquire data. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 20px\">\n",
    "\n",
    "## Sumário  <a class=\"tocSkip\">\n",
    "### Aquisição de dados com recurso a APIs<a class=\"tocSkip\">\n",
    "\n",
    "Introdução dos alunos à aquisição de dados com recurso a APIs\n",
    "    \n",
    "## Class Summary  <a class=\"tocSkip\">\n",
    "### Data acquisition using APIs <a class=\"tocSkip\">\n",
    "Introducing students to data acquisition using APIs.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API é um conjunto de rotinas e padrões de programação para acesso a um aplicativo de software ou plataforma baseado na Web. Uma API é criada quando uma empresa de software tem a intenção de que outros criadores de software desenvolvam produtos associados ao seu serviço. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando uma pessoa acessa uma página de um hotel, por exemplo, é possível visualizar dentro do próprio site o mapa do Google Maps para saber a localização do estabelecimento e verificar qual o melhor caminho para chegar até lá. Esse procedimento é realizado por meio de uma API, onde os desenvolvedores do site do hotel utilizam do código do Google Maps para inseri-lo num determinado local de sua página."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<div align=\"center\"><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/s7wmiS2mSXY\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe></div>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde o seu surgimento que o JSON rapidamente se tornou no \"de facto standard\" para troca de informação. A obtenção de um ficheiro JSON decorre habitualmente no decurso da execução de uma API. A figura abaixo ilustra um ficheiro JSON:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.di.ubi.pt/~rcampos/assets/img_tutorials/Text2Analytics/json.jpg\" width=\"500\" height=\"500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como pode ver, o JSON suporta tipos de dados primitivos (strings, numbers, floats, etc), assim como listas encadeadas e objetos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código seguinte permite obter, em formato JSON, os resultados da api [textsearch](https://github.com/arquivo/pwa-technologies/wiki/Arquivo.pt-API) do [arquivo.pt](https://arquivo.pt/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No código, fazemos uso de headers. API headers are like an extra source of information for each API call you make. Their job is to represent the meta-data associated with an API request and response. If you ever encounter issues with an API, the first place you should look is the headers, since they can help you track down any potential issues. [https://serpapi.com/blog/how-to-reduce-chance-of-being-blocked-while-web/]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A user agent (any software, acting on behalf of a user) is a string that a browser or application sends to each website you visit. A typical user agent string contains details like – the application type, operating system, software vendor, or software version of the requesting software user agent. Web servers use this data to assess the capabilities of your computer, optimizing a page’s performance and display. **Most websites block requests that come in without a valid browser as a User-Agent**. User-Agents are sent as a request header called `User-Agent`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most basic header and usually, for most websites, it will be enough, but user-agent does not guarantee that your request won't be declined or blocked. In basic explanation, user-agent is needed to act as a \"real\" user visit, which is also known as user-agent spoofing, when bot or browser send a fake user-agent string to announce themselves as a different client.\n",
    "\n",
    "**The reason why request might be blocked is that, for example in Python requests library, default user-agent is python-requests and websites understands that it's a bot and might block a request in order to protect the website from overload, if there's a lot of requests being sent.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para saber o seu user-agent consulte o seguinte link: https://router-network.com/tools/what-is-my-user-agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionalmente, é possível especificar um [timeout](https://linuxpip.org/python-requests-timeout/): \n",
    "\n",
    "- The **connect** timeout is the number of seconds Requests will wait for your client to establish a connection to a remote machine\n",
    "\n",
    "- Once your client has connected to the server and sent the HTTP request, the **read** timeout is the number of seconds the client will wait for the server to send a response. (Specifically, it’s the number of seconds that the client will wait between bytes sent from the server. In 99.9% of cases, this is the time before the server sends the first byte).\n",
    "\n",
    "Most requests to external servers should have a timeout attached, in case the server is not responding in a timely manner. By default, requests do not time out unless a timeout value is set explicitly. Without a timeout, your code may hang for minutes or more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O exemplo abaixo especifica um timeout de **5seg** (tanto para o **connect** como para o **read**). Se o cliente não conseguir estabelecer conexão com o servidor no espaço desses 5seg, ou, se após a conexão o servidor da API não devolver a resposta no espaço de 5seg, a biblioteca requests lança uma exceção e termina a conexão com o servidor. Note que terminar uma conexão não é sinómino de que o processo termine no servidor. Na verdade o servidor vai continuar a executar o pedido do utilizador (uma vez que este já está em execução), simplesmente não o vai devolver ao utilizador (o que é particularmente útil no caso de o sistema efetuar cache dos pedidos do utilizador, significando que a resposta estará em cache aquando do próximo pedido)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pretender especificar timeouts diferentes para o **connect** e para o **read** deverá fazê-lo desta forma: `timeout=(5, 27)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get(https://arquivo.pt/textsearch, params={'q': \"António Costa\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.exceptions import Timeout\n",
    "\n",
    "url_api = \"https://arquivo.pt/textsearch\"\n",
    "\n",
    "query = \"António Costa\"\n",
    "\n",
    "headers={\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:100.0) Gecko/20100101 Firefox/100.0 \"}\n",
    "\n",
    "payload = {'q': query}\n",
    "try:\n",
    "    r = requests.get(url_api, params=payload, headers=headers, timeout = 50)\n",
    "    print(r.url)\n",
    "except Timeout:\n",
    "    print('Timeout has been raised.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para visualizar os resultados pode pegar no URL gerado e colocá-lo num browser (e.g., Firefox). Note que a visualização dos resultados no Chrome obriga à instalação de um extensão (e.g., JSon View: https://chrome.google.com/webstore/detail/jsonview/chklaanhfefbnpoihckbnefhakgolnmc?hl=pt-PT]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método `json` do módulo `requests` converte esse texto numa estrutura de Python (e.g. ,dicionário) permitindo dessa forma que o JSON possa ser usado nos programas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O fato de ser um dicionário permite-nos imprimir todo o conteúdo do ficheiro JSON. Por uma questão de legibilidade vamos atribuir o json obtido a uma variável denominada `content` e que passaremos a usar daqui para frente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = r.json()\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impressao com recurso ao pretty print - mais entendivel\n",
    "import pprint\n",
    "pprint.pprint(content['response_items'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou ainda mais entendível:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(json.dumps(content['response_items'], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para iterar sobre os resultados recorremos a um ciclo for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in content['response_items']:\n",
    "    print(element['title'])\n",
    "    print(element['linkToArchive'])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recorra à api do Arquivo.pt (`https://arquivo.pt/textsearch`) para obter notícias acerca do `barack obama`. Restrinja a sua pesquisa ao site do jornal público (considere o seguinte parâmetro: 'siteSearch': 'http://www.publico.pt') e a um total de 2000 maxitems (considere o seguinte parâmetro: 'maxItems':2000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.exceptions import Timeout\n",
    "\n",
    "#especifique o endpoint\n",
    "url_api = \"\"\n",
    "\n",
    "#especifique a sua query\n",
    "query = \"\"\n",
    "\n",
    "headers={\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:100.0) Gecko/20100101 Firefox/100.0 \"}\n",
    "\n",
    "#acrescente ao payload o parâmetro sitesearch e o parâmetro maxItems\n",
    "payload = {'q': query}\n",
    "\n",
    "try:\n",
    "    r = requests.get(url_api, params=payload, headers=headers, timeout = 5)\n",
    "    print(r.url)\n",
    "except Timeout:\n",
    "    print('Timeout has been raised.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clique duas vezes <b>aqui</b> para aceder à solução completa\n",
    "<!--\n",
    "import requests\n",
    "from requests.exceptions import Timeout\n",
    "\n",
    "#especifique o endpoint\n",
    "url_api = \"https://arquivo.pt/textsearch\"\n",
    "\n",
    "#especifique a sua query\n",
    "query = \"barack obama\"\n",
    "\n",
    "headers={\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:100.0) Gecko/20100101 Firefox/100.0 \"}\n",
    "\n",
    "#acrescente ao payload o parâmetro sitesearch  e o parâmetro maxItems\n",
    "payload = {'q': query, 'siteSearch': 'http://www.publico.pt', 'maxItems':2000}}\n",
    "\n",
    "try:\n",
    "    r = requests.get(url_api, params=payload, headers=headers, timeout = 5)\n",
    "    print(r.url)\n",
    "except Timeout:\n",
    "    print('Timeout has been raised.')\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprima, para cada elemento obtido, o `title`, o `originalURL` e o `tstamp`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = r.json()\n",
    "\n",
    "for element in content['response_items']:\n",
    "    #imprima o title\n",
    "    #imprima o originalURL\n",
    "    #imprima o tstamp\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clique duas vezes <b>aqui</b> para aceder à solução completa\n",
    "<!--\n",
    "content = r.json()\n",
    "\n",
    "for element in content['response_items']:\n",
    "    print(element['title'])\n",
    "    print(element['originalURL'])\n",
    "    print(element['tstamp'])\n",
    "    print(\"\\n\")\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escreva um programa que guarde o conteúdo da variável `content` num ficheiro json denominado `arquivopt.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#escreva aqui o seu programa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clique duas vezes <b>aqui</b> para aceder à solução completa\n",
    "<!--\n",
    "import json\n",
    "\n",
    "path = \"data/\"\n",
    "\n",
    "file_name = \"arquivopt.json\"\n",
    "\n",
    "#gravar ficheiro com recurso a dump\n",
    "with open(path + file_name, \"w\") as outfile:\n",
    "    json.dump(content, outfile)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste módulo vamos explicar a forma de consumir web services no Python através do uso de APIs. Em concreto vamos consumir resultados a partir do:\n",
    "- New York Times\n",
    "- NIF.PT\n",
    "- Arquivo.pt images search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New York Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exercício abaixo vamos obter dados do New York Times. Para tal, deverá começar por criar uma conta, registar uma app, para finalmente pode aceder à sua API key. Veja como [aqui](https://developer.nytimes.com/get-started)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atualmente o NYT oferece acesso gratuito a uma série de [APIs](https://developer.nytimes.com/apis):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Archive API](https://developer.nytimes.com/docs/archive-product/1/overview): The New York Times Archive API allows developers to retrieve past New York Times articles by month going back to 1851. Users can get all articles for a given month as a JSON object by passing the desired year and month (both are required parameters). The Archive API is very useful if you want to build your own database of NYT article metadata. The response size can be large (~20mb).\n",
    "- [Article Search API](https://developer.nytimes.com/docs/articlesearch-product/1/overview): Use the Article Search API to look up articles by keyword.\n",
    "- [Books API](https://developer.nytimes.com/docs/books-product/1/overview): The Books API provides information about book reviews and The New York Times Best Sellers lists.\n",
    "- [Community API](https://developer.nytimes.com/docs/community-api-product/1/overview): Get comments from registered users on New York Times articles.\n",
    "- [Geographic API](https://developer.nytimes.com/docs/geo-product/1/overview): The New York Times Geographic API lets developers to get access to locations of the people, places, organizations, and descriptors that make up the controlled vocabulary found in the New York Times's metadata. \n",
    "- [Most Popular API](https://developer.nytimes.com/docs/most-popular-product/1/overview): The New York Times Most Popular API provides links and information about the most frequently e-mailed, shared and viewed blog posts and articles on the New York Times website. Developers can look at popularity based on views, emails and shares. In the case of the last method, developers can also look at shares on specific social networks, including Twitter, Facebook, Digg and more.\n",
    "- [Movie Reviews API](https://developer.nytimes.com/docs/movie-reviews-api/1/overview): The New York Times Movie Review API gives users access to movie reviews by the New York Times critics. The API gives access to over 22,000 New York Times movie reviews from today back to 1924. Using the Movie Reviews API you can query reviews and get data such as byline, critics pick, date updated, mpaa rating, title, headline, opening date, article link and multimedia. Users can search movie reviews by keywords or critic.\n",
    "- [Semantic API](https://developer.nytimes.com/docs/semantic-api-product/1/overview): The Semantic API complements the Articles API. With the Semantic API, you get access to the long list of people, places, organizations and other locations, entities and descriptors that make up the controlled vocabulary used as metadata by The New York Times (sometimes referred to as Times Tags and used for Times Topics pages.\n",
    "- [TimesTags API](https://developer.nytimes.com/docs/timestags-product/1/overview): New York Times has its own set of \"controlled meta-data,\" which it uses to categorize its stories. The TimesTags API provides access to this meta-data. \n",
    "- [Times Newswire API](https://developer.nytimes.com/docs/timeswire-product/1/overview): With the Times Newswire API, you can get links and metadata for Times articles as soon as they are published on NYTimes.com. The Times Newswire API provides an up-to-the-minute stream of published items.\n",
    "- [Top Stories](https://developer.nytimes.com/docs/top-stories-product/1/overview): The New York Times Top Stories API returns an array of articles currently on the specified section for arts, business and more. This includes services to access data for; arts, automobiles, books, business, fashion, food and more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No código abaixo vamos fazer uso da `Article Search API`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Article Search API**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NYT Article Search API allows you to search more than 2.8 million New York Times articles from `1981 to today`, retrieving headlines, abstracts, lead paragraphs and links to associated multimedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API supports the following type of searching: \n",
    "- Standard keyword searching\n",
    "- Date range: all articles from X date to Y date\n",
    "- Field search: search within any number of given fields, e.g., title:obama byline:dowd\n",
    "- Conjunction and disjunction (AND and NOT) operations, e.g., baseball yankees -\"red sox\"\n",
    "- Ordering by closest (variable ranking algorithms), newest and oldest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Article Search API also offers faceted searching. The available facets include Times-specific fields such as sections, taxonomic classifiers and controlled vocabulary terms (names of people, organizations and geographic locations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_name = \"keys.json\"\n",
    "\n",
    "with open(file_name, \"r\") as readfile:\n",
    "    data = json.load(readfile)\n",
    "\n",
    "key = data['nyt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "URL_REQUEST = \"https://api.nytimes.com/svc/search/v2/articlesearch.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exemplo abaixo pretendemos obter todos os artigos relacionados com a query `Donald Trump`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Donald Trump\"\n",
    "sort = \"relevance\"\n",
    "\n",
    "payload = {\n",
    "    'q': query, \n",
    "    'api-key': key,\n",
    "    'sort': sort\n",
    "}\n",
    "\n",
    "headers={\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:100.0) Gecko/20100101 Firefox/100.0 \"}\n",
    "\n",
    "r = requests.get(URL_REQUEST, params=payload, headers=headers)\n",
    "print(r.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contentsJSon = r.json()\n",
    "contentsJSon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código seguinte permite imprimir os resultados obtidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "print(f\"total = {contentsJSon['response']['meta']['hits']}\\n\")\n",
    "for doc in contentsJSon['response']['docs']:\n",
    "    print(f\"Source = {doc['source']}\")\n",
    "    print(f\"URL = {doc['web_url']}\")\n",
    "    print(f\"News Desk = {doc['news_desk']}\")\n",
    "    print(f\"PubDate = {datetime.datetime.strptime(doc['pub_date'], '%Y-%m-%dT%H:%M:%S+0000').strftime('%d-%m-%Y')}\")\n",
    "    print(f\"Snippet = {doc['snippet']}\")\n",
    "    print(f\"Abstract = {doc['abstract']}\")\n",
    "    print(f\"MainHeadline = {doc['headline']['main']}\")\n",
    "    print(f\"PrintHeadline = {doc['headline']['print_headline']}\")\n",
    "    print(f\"LeadParagraph = {doc['lead_paragraph']} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De seguida vamos guardar os resultados num conjunto de listas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "ListOfResults = []\n",
    "\n",
    "for doc in contentsJSon['response']['docs']:\n",
    "    ListOfResults.append({'source': doc['source'], \n",
    "                          'web_url': doc['web_url'],\n",
    "                          'news_desk': doc['news_desk'],\n",
    "                          'date': datetime.datetime.strptime(doc['pub_date'], \"%Y-%m-%dT%H:%M:%S+0000\").strftime(\"%d-%m-%Y\"),\n",
    "                          'snippet': doc['snippet'],\n",
    "                          'abstract': doc['abstract'],\n",
    "                          'headline_main': doc['headline']['main'],\n",
    "                          'headline_print': doc['headline']['print_headline'],\n",
    "                          'lead_paragraph': doc['lead_paragraph']\n",
    "                         })\n",
    "\n",
    "ListOfResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na posse destes dados podemos agora mostrá-los num dataframe pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(ListOfResults)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para guardar o dataframe em HTML use o seguinte código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_html(\"donald trump.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ou:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = df.to_html()\n",
    "with open(\"donald trump.html\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poderiamos agora por exemplo restringir os resultados ao news_desk Magazine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['news_desk'] == 'Politics']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NIF.PT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O [NIF.PT](https://www.nif.pt) é um serviço gratuito de pesquisa de NIF portugueses, que permite procurar, descobrir e consultar NIF de empresas. Para facilitar a tarefa de validar programaticamente um nif, este website disponibiliza uma api."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recorra à [api](https://www.nif.pt/api) disponibilizada pelo NIF.PT para consultar informações acerca do número de contribuinte de uma empresa à sua escolha. Imprima o resultado do campo `title`, `address`, `pc4-pc3`, `city`, `activity`, `cae`, `email`, `phone`, `website`, `fax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_name = \"keys.json\"\n",
    "\n",
    "with open(file_name, \"r\") as readfile:\n",
    "    data = json.load(readfile)\n",
    "\n",
    "key = data['nif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insira o seu código aqui\n",
    "\n",
    "import requests\n",
    "from requests.exceptions import Timeout\n",
    "\n",
    "url_api = \"http://www.nif.pt/?json=1\"\n",
    "\n",
    "nif = \"501836926\"\n",
    "\n",
    "headers={\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:100.0) Gecko/20100101 Firefox/100.0 \"}\n",
    "\n",
    "payload = {'q': nif, 'key':key}\n",
    "try:\n",
    "    r = requests.get(url_api, params=payload, headers=headers, timeout = 50)\n",
    "    print(r.url)\n",
    "except Timeout:\n",
    "    print('Timeout has been raised.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = r.json()\n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clique duas vezes <b>aqui</b> para aceder à solução\n",
    "<!--\n",
    "import requests\n",
    "#Nao se esqueca de inserir a key no codigo abaixo\n",
    "key = ''\n",
    "NIF = 501836926\n",
    "url_api = 'http://www.nif.pt/?json=1'\n",
    "payload = { 'q': NIF, 'key': key}\n",
    "\n",
    "headers={\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:100.0) Gecko/20100101 Firefox/100.0 \"}\n",
    "\n",
    "r = requests.get(url_api, params=payload, headers=headers)\n",
    "print(r.url)\n",
    "contents =r.json()\n",
    "print(contents)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clique duas vezes <b>aqui</b> para aceder ao resto da solução\n",
    "<!--\n",
    "content = contents['records'][str(NIF)]\n",
    "print(f\"Title = {content['title']}\")\n",
    "print(f\"Address = {content['address']}\")\n",
    "print(f\"Postal Code = {content['pc4']} - {content['pc3']}\")\n",
    "print(f\"City = {content['city']}\")\n",
    "print(f\"Activity = {content['activity']}\")\n",
    "print(f\"CAE = {content['cae']}\")\n",
    "print(f\"Email = {content['contacts']['email']}\")\n",
    "print(f\"Phone = {content['contacts']['phone']}\")\n",
    "print(f\"Website = {content['contacts']['website']}\")\n",
    "print(f\"Fax = {content['contacts']['fax']}\")\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desenhe agora um programa que lhe permita obter a informação (title e address) de dois NIFs à sua escolha. Não se esqueça que o serviço NIF.pt apenas permite um único request por minuto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insira o seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clique duas vezes <b>aqui</b> para aceder à solução\n",
    "<!--\n",
    "import requests\n",
    "import time\n",
    "\n",
    "import json\n",
    "\n",
    "file_name = \"keys.json\"\n",
    "\n",
    "with open(file_name, \"r\") as readfile:\n",
    "    data = json.load(readfile)\n",
    "\n",
    "key = data['nif']\n",
    "\n",
    "url_api = 'http://www.nif.pt/?json=1'\n",
    "\n",
    "ListOfNIFs = [501836926, 510462553]\n",
    "\n",
    "ListOfResults = []\n",
    "\n",
    "headers={\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:100.0) Gecko/20100101 Firefox/100.0 \"}\n",
    "\n",
    "for nif in ListOfNIFs:\n",
    "    payload = { 'q': nif, 'key': key}\n",
    "    \n",
    "    r = requests.get(url_api, params=payload, headers = headers)\n",
    "    contents =r.json()\n",
    "    \n",
    "    title = contents['records'][str(nif)]['title']\n",
    "    address = contents['records'][str(nif)]['address']\n",
    "    \n",
    "    ListOfResults.append({'title':title, 'address': address})\n",
    "    time.sleep(61)\n",
    "    \n",
    "ListOfResults\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente envie a informação coletada para um dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insira o seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clique duas vezes <b>aqui</b> para aceder à solução\n",
    "<!--\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(ListOfResults)\n",
    "df\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arquivo.pt Images Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere a seguinte página web (https://github.com/arquivo/pwa-technologies/wiki/ImageSearch-API-v1.1-(beta) que descreve o funcionamento da API de imagens do Arquivo.pt. Escreva um programa que permita obter dados a partir dessa API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arquivo.pt/imagesearch?q=Avatar&maxItems=100\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "URL_REQUEST = \"https://arquivo.pt/imagesearch\"\n",
    "query = 'Avatar'\n",
    "payload = {\n",
    "    'q': query,\n",
    "    'maxItems': 100\n",
    "}\n",
    "\n",
    "headers={\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:100.0) Gecko/20100101 Firefox/100.0 \"}\n",
    "\n",
    "r = requests.get(URL_REQUEST, params=payload, headers = headers)\n",
    "print(r.url)\n",
    "contents = r.json()\n",
    "for counter, content in enumerate(contents['responseItems'], start=1):\n",
    "    print(counter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código seguinte exemplifica a obtenção de texto a partir da API da wikipedia. Os resultados aqui devolvidos são iguais aos obtidos a partir do package python da wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.exceptions import Timeout\n",
    "\n",
    "url_api = \"https://pt.wikipedia.org/w/api.php\"\n",
    "\n",
    "query = \"António Costa\"\n",
    "\n",
    "headers={\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:100.0) Gecko/20100101 Firefox/100.0 \"}\n",
    "\n",
    "payload = {'action': 'query',\n",
    "            'format': 'json',\n",
    "            'titles': query,\n",
    "            'prop': 'extracts',\n",
    "            'exintro': True,\n",
    "            'explaintext': True\n",
    "        }\n",
    "\n",
    "try:\n",
    "    r = requests.get(url_api, params=payload, headers=headers, timeout = 5)\n",
    "    print(r.url)\n",
    "except Timeout:\n",
    "    print('Timeout has been raised.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da execução do código seuinte é possível observar que o texto relativo a cada entidade aparece associado a uma página cujo número é dinamicamente obtido aquando da chamada à API (98576 no caso da query ser António Costa; 1286 no caso de ser Mário Soares) dificultando dessa forma o acesso aos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = r.json()\n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De facto, a obtenção dos dados em \"extract\" obrigaria à especificação do número em questão, algo impraticável de automatizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content['query']['pages']['98576']['extract']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma a ultrapassarmos essa dificuldade recorremos ao comando `next-iter` que nos permite aceder programaticamente a cada uma das chaves do dicionário. Assim, `next(iter(content['query']))` dá-nos acesso à próxima chave, pages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(content['query']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da mesma forma que `next(iter(content['query']['pages']))` nos dá acesso à chave `98576`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(content['query']['pages']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chegados aqui podemos recorrer a `values` para obter os valores associados à chave `98576`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(content['query']['pages'].values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E em concreto ao texto existente no campo `extract`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(content['query']['pages'].values()))['extract']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Public API Portugal](https://github.com/devpt-org/public-data-portugal)\n",
    "- [Awesome Portugal Data](https://github.com/rgllm/awesome-portugal-data)\n",
    "- [Covid19](https://covid19api.com/)\n",
    "- [News API](https://newscatcherapi.com/)\n",
    "- [Media Cloud](https://mediacloud.org/support)\n",
    "- [Even Registry](https://eventregistry.org/)\n",
    "- [Google Search API](https://serpapi.com/)\n",
    "- [Dandelion API](https://dandelion.eu/)\n",
    "- [The best api for live music](https://www.songkick.com/developer)\n",
    "- [lexalytics](https://www.lexalytics.com/)\n",
    "- [9 crime APIs](https://rapidapi.com/collection/crime)\n",
    "- [top-50 most popular APIs 2020](https://rapidapi.com/blog/most-popular-api/?utm_source=google&utm_medium=cpc&utm_campaign=Beta_100613405446&utm_term=%2Bpopular%20%2Bapi_b&gclid=Cj0KCQjwoJX8BRCZARIsAEWBFMK-3YAO7LENBEwh2P7rE82Go5jgCST8xxwC36fN7v3DUtGwHw2mz90aAosIEALw_wcB)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "238.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
