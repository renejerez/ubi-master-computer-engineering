{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "131fd887",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid black\">\n",
    "<b><center><font size=\"4\">Data Science</font></center></b>\n",
    "\n",
    "<b><center><font size=\"3\">Manipulação e Análise de Dados com Pandas Dataframes</font></center></b>\n",
    "\n",
    "<b><center><font size=\"2\">11 - Data Analysis without Programming</font></center></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1a614a",
   "metadata": {},
   "source": [
    "**Notebook Developed by**: [Ricardo Campos](https://www.di.ubi.pt/~rcampos)<br>\n",
    "**email:**  ricardo.campos@ubi.pt<br>\n",
    "**Affiliation:** *Assistant Professor* @ [University of Beira Interior](http://www.ubi.pt);\n",
    "*Researcher* @ [LIAAD](https://www.inesctec.pt/en/centres/liaad)-[INESC TEC](https://www.inesctec.pt/en)\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p><a href=\"11DataAnalysisWithoutProgramming.ipynb\" title=\"Download Notebook\" download><img src=\"https://www.di.ubi.pt/~rcampos/assets/img_tutorials/download.jpg\" align = \"left\" width=\"50\" height=\"50\" alt=\"Download Notebook\"></a></p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d9f2f5",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#PandasAI\" data-toc-modified-id=\"PandasAI-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>PandasAI</a></span><ul class=\"toc-item\"><li><span><a href=\"#Installation\" data-toc-modified-id=\"Installation-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Installation</a></span><ul class=\"toc-item\"><li><span><a href=\"#PandasAI\" data-toc-modified-id=\"PandasAI-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>PandasAI</a></span></li><li><span><a href=\"#OpenAI\" data-toc-modified-id=\"OpenAI-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>OpenAI</a></span><ul class=\"toc-item\"><li><span><a href=\"#For-Linux-or-Mac:\" data-toc-modified-id=\"For-Linux-or-Mac:-1.1.2.1\"><span class=\"toc-item-num\">1.1.2.1&nbsp;&nbsp;</span>For Linux or Mac:</a></span></li><li><span><a href=\"#For-Windows\" data-toc-modified-id=\"For-Windows-1.1.2.2\"><span class=\"toc-item-num\">1.1.2.2&nbsp;&nbsp;</span>For Windows</a></span></li><li><span><a href=\"#For-Google-Colab\" data-toc-modified-id=\"For-Google-Colab-1.1.2.3\"><span class=\"toc-item-num\">1.1.2.3&nbsp;&nbsp;</span>For Google Colab</a></span></li></ul></li></ul></li><li><span><a href=\"#Usage\" data-toc-modified-id=\"Usage-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Usage</a></span><ul class=\"toc-item\"><li><span><a href=\"#SmartDataFrame\" data-toc-modified-id=\"SmartDataFrame-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>SmartDataFrame</a></span></li><li><span><a href=\"#Multiple-Dataframes\" data-toc-modified-id=\"Multiple-Dataframes-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Multiple Dataframes</a></span></li><li><span><a href=\"#Connectors\" data-toc-modified-id=\"Connectors-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Connectors</a></span></li><li><span><a href=\"#CSV\" data-toc-modified-id=\"CSV-1.2.4\"><span class=\"toc-item-num\">1.2.4&nbsp;&nbsp;</span>CSV</a></span></li></ul></li><li><span><a href=\"#Limitations-of-Pandas\" data-toc-modified-id=\"Limitations-of-Pandas-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Limitations of Pandas</a></span></li><li><span><a href=\"#When-not-to-use-PandasAI?\" data-toc-modified-id=\"When-not-to-use-PandasAI?-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>When not to use PandasAI?</a></span></li></ul></li><li><span><a href=\"#Autoviz\" data-toc-modified-id=\"Autoviz-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Autoviz</a></span><ul class=\"toc-item\"><li><span><a href=\"#Installation\" data-toc-modified-id=\"Installation-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Installation</a></span></li><li><span><a href=\"#Usage\" data-toc-modified-id=\"Usage-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Usage</a></span></li></ul></li><li><span><a href=\"#Bamboolib\" data-toc-modified-id=\"Bamboolib-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Bamboolib</a></span><ul class=\"toc-item\"><li><span><a href=\"#Installation\" data-toc-modified-id=\"Installation-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Installation</a></span></li><li><span><a href=\"#Import\" data-toc-modified-id=\"Import-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Import</a></span></li><li><span><a href=\"#Data-Preparation\" data-toc-modified-id=\"Data-Preparation-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Data Preparation</a></span></li><li><span><a href=\"#Data-Transformation\" data-toc-modified-id=\"Data-Transformation-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Data Transformation</a></span></li><li><span><a href=\"#Data-Visualization\" data-toc-modified-id=\"Data-Visualization-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Data Visualization</a></span></li><li><span><a href=\"#Data-Exploration\" data-toc-modified-id=\"Data-Exploration-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Data Exploration</a></span></li></ul></li><li><span><a href=\"#Bibliography\" data-toc-modified-id=\"Bibliography-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Bibliography</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319849ff",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 20px\">\n",
    "\n",
    "## Objetivos de aprendizagem  <a class=\"tocSkip\">\n",
    "    \n",
    "No final deste notebook o aluno deverá ter conhecimento de plataformas de análise de dados sem recurso à programação.\n",
    "\n",
    "\n",
    "## Learning Objectives  <a class=\"tocSkip\">\n",
    "       \n",
    "When concluding this notebook, the student should be aware of data analysis framework not involving programming. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c29df5b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 20px\">\n",
    "\n",
    "## Sumário  <a class=\"tocSkip\">\n",
    "### Frameworks de Análise de Dados sem recurso à Programação <a class=\"tocSkip\">\n",
    "\n",
    "Introdução dos alunos a frameworks de análise de dados sem recurso à programação\n",
    "- PandasAI\n",
    "    \n",
    "## Data Analysis Frameworks without Programming  <a class=\"tocSkip\">\n",
    "### Vectorization <a class=\"tocSkip\">\n",
    "Introducing students data analysis frameworks without programming\n",
    "- PandasAI\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f95124",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49065f1f",
   "metadata": {},
   "source": [
    "## PandasAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c5202a",
   "metadata": {},
   "source": [
    "[PandasAI](https://github.com/gventuri/pandas-ai) is a Python library that integrates generative artificial intelligence capabilities into Pandas, making data frames conversational. You can speak with your dataset, talk to your data and get fast responses. Pandas AI does not replace Pandas, it just gives it a big push!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ccec73",
   "metadata": {},
   "source": [
    "With the help of OpenAI API, Pandas AI aims to achieve the goal of virtually talking with a machine to output the results you want rather than having to program the task yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b49b1a4",
   "metadata": {},
   "source": [
    "<b>Is Pandas AI replacing Pandas?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0401d40f",
   "metadata": {},
   "source": [
    "No, Pandas AI is not meant to replace Pandas. Though Pandas AI can easily perform simple tasks, it still faces difficulty performing some complex tasks like saving the dataframe or performing some complex functions like join, etc. Pandas AI is just an extension of Pandas, for now it cannot replace Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b54c24d",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43a4c05",
   "metadata": {},
   "source": [
    "#### PandasAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec86655f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandasai\n",
      "  Downloading pandasai-2.0.42-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting astor<0.9.0,>=0.8.1 (from pandasai)\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting duckdb<1 (from pandasai)\n",
      "  Downloading duckdb-0.10.2-cp311-cp311-win_amd64.whl.metadata (782 bytes)\n",
      "Collecting faker<20.0.0,>=19.12.0 (from pandasai)\n",
      "  Downloading Faker-19.13.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.3 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from pandasai) (3.1.3)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.7.1 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from pandasai) (3.8.0)\n",
      "Requirement already satisfied: openai<2 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from pandasai) (1.14.2)\n",
      "Collecting pandas==1.5.3 (from pandasai)\n",
      "  Downloading pandas-1.5.3-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.1.0 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from pandasai) (10.2.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from pandasai) (1.10.12)\n",
      "Collecting python-dotenv<2.0.0,>=1.0.0 (from pandasai)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from pandasai) (2.31.0)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.9.0 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from pandasai) (1.11.4)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from pandasai) (2.0.25)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from pandas==1.5.3->pandasai) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from pandas==1.5.3->pandasai) (2023.3.post1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from pandas==1.5.3->pandasai) (1.26.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from jinja2<4.0.0,>=3.1.3->pandasai) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.7.1->pandasai) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.7.1->pandasai) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.7.1->pandasai) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.7.1->pandasai) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.7.1->pandasai) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.7.1->pandasai) (3.0.9)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from openai<2->pandasai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from openai<2->pandasai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from openai<2->pandasai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from openai<2->pandasai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from openai<2->pandasai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from openai<2->pandasai) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.31.0->pandasai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.31.0->pandasai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.31.0->pandasai) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.31.0->pandasai) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from sqlalchemy<3,>=1.4->pandasai) (3.0.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2->pandasai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2->pandasai) (0.14.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas==1.5.3->pandasai) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rene_\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2->pandasai) (0.4.6)\n",
      "Downloading pandasai-2.0.42-py3-none-any.whl (142 kB)\n",
      "   ---------------------------------------- 0.0/142.6 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 133.1/142.6 kB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 133.1/142.6 kB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 133.1/142.6 kB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 133.1/142.6 kB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 133.1/142.6 kB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 133.1/142.6 kB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- 142.6/142.6 kB 424.2 kB/s eta 0:00:00\n",
      "Downloading pandas-1.5.3-cp311-cp311-win_amd64.whl (10.3 MB)\n",
      "   ---------------------------------------- 0.0/10.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/10.3 MB 9.4 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.3/10.3 MB 11.7 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.0/10.3 MB 11.8 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.1/10.3 MB 14.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.3/10.3 MB 16.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.3/10.3 MB 16.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.5/10.3 MB 17.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.8/10.3 MB 19.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.0/10.3 MB 19.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.3/10.3 MB 6.9 MB/s eta 0:00:00\n",
      "Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading duckdb-0.10.2-cp311-cp311-win_amd64.whl (9.8 MB)\n",
      "   ---------------------------------------- 0.0/9.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.7/9.8 MB 13.9 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.5/9.8 MB 23.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.9/9.8 MB 25.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.7/9.8 MB 28.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.6/9.8 MB 30.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.5/9.8 MB 26.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/9.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/9.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/9.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/9.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/9.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/9.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/9.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/9.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/9.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/9.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/9.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/9.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/9.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/9.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/9.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/9.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/9.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/9.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/9.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/9.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/9.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/9.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.8/9.8 MB 6.6 MB/s eta 0:00:00\n",
      "Downloading Faker-19.13.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.9/1.7 MB 18.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 22.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 22.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 22.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 22.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 6.5 MB/s eta 0:00:00\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv, duckdb, astor, pandas, faker, pandasai\n",
      "Successfully installed astor-0.8.1 duckdb-0.10.2 faker-19.13.0 pandas-1.5.3 pandasai-2.0.42 python-dotenv-1.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script dotenv.exe is installed in 'C:\\Users\\rene_\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script faker.exe is installed in 'C:\\Users\\rene_\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install pandasai --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fada26",
   "metadata": {},
   "source": [
    "#### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ae9ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718838c0",
   "metadata": {},
   "source": [
    "In order to make use of the new Pandas AI library, you will need an OpenAI key. If you don’t have an account with OpenAI, you will need to create one. Note that because there is a charge for the API, you will need to provide a means of payment.\n",
    "To obtain the key go to https://platform.openai.com/playground, click your account name and then View API keys. When you are on the API keys page, click Create new secret key and make a copy of your key. This key is a long string of characters starting with sk-."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8029dc74",
   "metadata": {},
   "source": [
    "Once you have your key, the best practice is to export it as an environment variable. This will allow your application to access the key without writing it directly in your code. Here is how to do that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed152c6",
   "metadata": {},
   "source": [
    "**Linux or Mac**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab22d475",
   "metadata": {},
   "source": [
    "``` python\n",
    "# set environment variable OPENAI_API_KEY for current session\n",
    "export OPENAI_API_KEY=sk-...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9cfe20",
   "metadata": {},
   "source": [
    "Then open a new prompt and try the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dcdaa4",
   "metadata": {},
   "source": [
    "```python\n",
    "# check that environment variable was set\n",
    "echo $OPENAI_API_KEY\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdc5586",
   "metadata": {},
   "source": [
    "**Windows**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e9d6c7",
   "metadata": {},
   "source": [
    "```python\n",
    "# set environment variable OPENAI_API_KEY for current session\n",
    "setx OPENAI_API_KEY “<yourkey>”\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a345aeaa",
   "metadata": {},
   "source": [
    "Then open a new prompt and try the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3febc719",
   "metadata": {},
   "source": [
    "```python\n",
    "# check that environment variable was set\n",
    "echo %OPENAI_API_KEY%\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd821928",
   "metadata": {},
   "source": [
    "Alternatively, you may also create it as an environmental variable through the control panel: https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3ce6c9",
   "metadata": {},
   "source": [
    "**For Google Colab**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02bc6c0",
   "metadata": {},
   "source": [
    "In Google Colab you may define the environment variable as follows, however, this will disclose it to others, should you share the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be8cedc",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"key\"\n",
    "print(os.getenv('OPENAI_API_KEY'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a24da8",
   "metadata": {},
   "source": [
    "Alternatively, you can save the credentials in an `.env` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8222fe",
   "metadata": {},
   "source": [
    "<b>Step 1:</b> Login into your Google Drive account: https://drive.google.com/drive/my-drive\n",
    "\n",
    "<b>Step 2:</b> In your Google Drive account create a new folder named `credentials`.\n",
    "\n",
    "<b>Step 3:</b> In your computer create a file `.env` with the following contents:\n",
    "```python\n",
    "OPENAI_API_KEY=\"sk-....\"\n",
    "```\n",
    "\n",
    "<b>Step 4:</b> Copy the `.env` to the `credentials` folder in your Google Drive account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb88f6d",
   "metadata": {},
   "source": [
    "<b>Step 5:</b> Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee18be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive    \n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f449da",
   "metadata": {},
   "source": [
    "<b>Step 6:</b> Load the key installing and using the `dotenv` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "658a7596",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "140c1d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "#path = '/content/drive/MyDrive/credentials/.env'\n",
    "#load_dotenv(path)\n",
    "OPENAI_API_KEY = '27RlngSpZU6HndublUwwT3BlbkFJnFTIsqQ8b0jiM3MT6zv6'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846623e5",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016f3a1f",
   "metadata": {},
   "source": [
    "#### SmartDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5779c13b",
   "metadata": {},
   "source": [
    "Once you start on your notebook, you will need to import the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9a9588c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandasai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandasai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SmartDataframe\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandasai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Instantiate a LLM\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandasai'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandasai import SmartDataframe\n",
    "from pandasai.llm import OpenAI\n",
    "\n",
    "# Instantiate a LLM\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac883cb3",
   "metadata": {},
   "source": [
    "Next, consider the following dataframe as a running example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbc308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"country\": [\"United States\", \"United Kingdom\", \"France\", \"Germany\", \"Italy\", \"Spain\", \"Canada\", \"Australia\", \"Japan\", \"China\"],\n",
    "    \"gdp\": [19294482071552, 2891615567872, 2411255037952, 3435817336832, 1745433788416, 1181205135360, 1607402389504, 1490967855104, 4380756541440, 14631844184064],\n",
    "    \"happiness_index\": [6.94, 7.16, 6.66, 7.07, 6.38, 6.4, 7.23, 7.22, 5.87, 5.12]\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f4a35d",
   "metadata": {},
   "source": [
    "We then redefine the `df` as a SmartDataFrame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def371e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = SmartDataframe(df, config={\"llm\": llm})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff8267c",
   "metadata": {},
   "source": [
    "PandasAI mainly takes 2 parameters as input, first the dataset and second a prompt which is the query or question asked. Executing your prompt using PandasAI sends a request to the OpenAI server on which the LLM is hosted. The LLM processes the request, converts the query into appropriate Python code, and then uses pandas to calculate the answer. It returns the answer to PandasAI, then outputs it to your screen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52c68b8",
   "metadata": {},
   "source": [
    "You can ask the system to retrieve the top-5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92bcc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.chat('Show the first 5 rows of data in tabular form')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f715002e-b77c-44af-b1b2-b03a6304dd05",
   "metadata": {},
   "source": [
    "To list all columns names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01f0a62-38a8-4d0b-87d4-e706571dcfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.chat(\"print out the column names of the dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84e0f4b",
   "metadata": {},
   "source": [
    "Filter data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a180cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.chat(\"Show the data in the row where the country is France\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf6437b",
   "metadata": {},
   "source": [
    "For example, you can ask PandasAI to find all the rows in a DataFrame where the value of a column is greater than 5, and it will return a DataFrame containing only those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d61e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.chat('Which are the 5 happiest countries?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c827813a",
   "metadata": {},
   "source": [
    "Of course, you can also ask PandasAI to perform more complex queries. For example, you can ask PandasAI to find the sum of the GDPs of the 2 unhappiest countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbc06f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.chat('What is the sum of the GDPs of the 2 unhappiest countries?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95241dc1",
   "metadata": {},
   "source": [
    "You can also ask PandasAI to draw a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186e3077",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.chat(\"Plot a unique bar plot for the columns 'gdp' and 'Country'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75395650",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.chat(\"Plot a histogram for each column in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0bba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.chat(\"Plot a box plot for the column 'happiness index'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a84b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.chat(\"Plot a scatter plot for the columns 'gdp' and 'happiness index'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924cd782",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.chat(\"Plot a heatmap correlation matrix for the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b41f12a",
   "metadata": {},
   "source": [
    "#### Multiple Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ab5ec1",
   "metadata": {},
   "source": [
    "Additionally, you can also pass in multiple dataframes to PandasAI and ask questions relating them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da0467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandasai import SmartDatalake\n",
    "from pandasai.llm import OpenAI\n",
    "\n",
    "employees_data = {\n",
    "    'EmployeeID': [1, 2, 3, 4, 5],\n",
    "    'Name': ['John', 'Emma', 'Liam', 'Olivia', 'William'],\n",
    "    'Department': ['HR', 'Sales', 'IT', 'Marketing', 'Finance']\n",
    "}\n",
    "\n",
    "salaries_data = {\n",
    "    'EmployeeID': [1, 2, 3, 4, 5],\n",
    "    'Salary': [5000, 6000, 4500, 7000, 5500]\n",
    "}\n",
    "\n",
    "employees_df = pd.DataFrame(employees_data)\n",
    "salaries_df = pd.DataFrame(salaries_data)\n",
    "\n",
    "\n",
    "llm = OpenAI()\n",
    "dl = SmartDatalake([employees_df, salaries_df], config={\"llm\": llm})\n",
    "dl.chat(\"Whose Name gets paid the most?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b08bb6",
   "metadata": {},
   "source": [
    "#### Connectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fd7a87",
   "metadata": {},
   "source": [
    "PandasAI can also be used in several other [scenarios](https://github.com/gventuri/pandas-ai/tree/main/examples)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4adf71c",
   "metadata": {},
   "source": [
    "PandasAI provides a number of connectors that allow you to connect to different data sources. These connectors are designed to be easy to use, even if you are not familiar with the data source or with PandasAI.  One interesting example is the link to YahooFinance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d0152c-68ca-4966-9501-7bee23ede855",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbe7c16-b883-40c5-a77d-12ffb00df0d4",
   "metadata": {},
   "source": [
    "Observe that it will hallucinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd61e3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasai.connectors.yahoo_finance import YahooFinanceConnector\n",
    "from pandasai import SmartDataframe\n",
    "from pandasai.llm import OpenAI\n",
    "\n",
    "yahoo_connector = YahooFinanceConnector(\"BTC-USD\")\n",
    "\n",
    "llm = OpenAI()\n",
    "sdf = SmartDataframe(yahoo_connector, config={\"llm\": llm})\n",
    "\n",
    "response = sdf.chat(\"What was the opening price of Bitcoin today\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1358531",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.chat(\"Plot the chart of Bitcoin over time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f3dbfd",
   "metadata": {},
   "source": [
    "You can find more info about the connectors (and many more connectors) here: https://docs.pandas-ai.com/en/latest/connectors/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ba3d8c",
   "metadata": {},
   "source": [
    "#### CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18195e4c",
   "metadata": {},
   "source": [
    "In the following we will be working with a CSV file. For that, we will be using the medical charges data which is available here  for [download](https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv). Download and save that file under the data folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21fbe85",
   "metadata": {},
   "source": [
    "The data doesn’t contain any missing values, thus we ask you to deliberately change the first value for the <b>charges</b> column to null (NaN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504aa70e",
   "metadata": {},
   "source": [
    "To load the data use the following code. The `charges` column is the amount of money an individual pays for an insurance policy covering healthcare. The `BMI` is the `Body Mass Index`. It is a person's weight in kilograms (or pounds) divided by the square of height in meters (or feet). A high BMI can indicate high body fatness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37cd1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/insurance.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfeecab",
   "metadata": {},
   "source": [
    "To work with PandaAI import the following libraries and instantiate the OpenAI LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5c9a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasai import SmartDataframe\n",
    "from pandasai.llm import OpenAI\n",
    "\n",
    "# Instantiate a LLM\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414faa74",
   "metadata": {},
   "source": [
    "Next, we create a smartdataframe object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0e85f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = SmartDataframe(df, config={\"llm\": llm})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d505b997",
   "metadata": {},
   "source": [
    "Let’s start prompting the system with one of the most basic questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94f71dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.chat(\"What is the size of the dataset?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68416bcf",
   "metadata": {},
   "source": [
    "Let's us check if the results retrieved are correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837be5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581e1de5",
   "metadata": {},
   "source": [
    "Next, we check how many null values exist in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116abf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.chat(\"How many null values are in the data? In which column?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c54ef0-1077-4891-82a0-00c961f954d4",
   "metadata": {},
   "source": [
    "Let's confirm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d3ed80-26db-490c-a25d-7d400a5287ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.isnull().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e7533f-cc2b-47c7-a0d4-bca646746317",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.chat(\"calculate the mean value of charges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9b976d",
   "metadata": {},
   "source": [
    "We then ask to impute the null value based on the mean of the charges column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c99325",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.chat(\"Impute the missing value - rounded to 2 decimal digits - in the data using the mean value. Output the head of the dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d374cddb-0663-4609-b38c-ba99fdb89583",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.chat(\"print out the records where age = 19, sex = female, bmi = 27.9, region = southwest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091bfd8a",
   "metadata": {},
   "source": [
    "Let's make a more complex prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade14d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''Which region has the greatest number of smokers and which has the lowest?\n",
    "            Include the values of both the greatest and lowest numbers in the answer.\n",
    "        '''\n",
    "\n",
    "sdf.chat(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94423e72",
   "metadata": {},
   "source": [
    "Let's confirm if the information printed by the model is actually correct (or not) by elaborating the corresponding pandas code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eca28e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_smoker = df[df['smoker']==\"yes\"].groupby('region').count()['smoker']\n",
    "min_region = df_smoker.idxmin() #to get the name of the region with min value\n",
    "min_value = min(df_smoker) #to get the min value\n",
    "\n",
    "max_region = df_smoker.idxmax() #to get the name of the region with max value\n",
    "max_value = max(df_smoker) #to get the max value\n",
    "\n",
    "print(f'The region with the greatest number of smokers is {max_region} with {max_value} smokers. The region with the lowest number of smokers is {min_region} with {min_value} smokers.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118c8da4",
   "metadata": {},
   "source": [
    "Now an even more difficult one. `What are the average charges of a female living in the north?` The region column contains 4 regions: `northeast`, `northwest`, `southeast`, and `southwest`. So, the north should contain both `northeast` and `northwest` regions. But can the LLM be able to understand this subtle but important detail? Let’s find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87184286",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''What are the average charges of a female living in the north region?\n",
    "            Provide the answer in form of a sentence to 2 decimal places.'''\n",
    "\n",
    "sdf.chat(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c03866",
   "metadata": {},
   "source": [
    "Let’s check the answer manually using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87abc26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "north_data = df[(df['sex'] == 'female') & \n",
    "                 ((df['region'] == 'northeast') |\n",
    "                  (df['region'] == 'northwest'))]\n",
    "north_data['charges'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5573db64",
   "metadata": {},
   "source": [
    "The above code outputs a different answer (which is the correct answer) than the LLM gave. In this case, the LLM wasn’t able to perform well. We can be more specific and tell the LLM what we mean by the north region and see if it can give the correct answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cc3835",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''What are the average charges of a female living in the north region?\n",
    "            The north region consists of both the northeast and northwest regions.\n",
    "            Provide the answer in form of a sentence to 2 decimal places.'''\n",
    "\n",
    "sdf.chat(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facf25ff",
   "metadata": {},
   "source": [
    "This time it gives the correct answer. As this was a tricky question, we must be more careful about our prompts and include relevant details, as the LLM might overlook these subtle differences. Therefore, you can see that we can’t trust the LLM blindly as it can generate incorrect responses sometimes due to incomplete prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6970033a",
   "metadata": {},
   "source": [
    "So far, we have seen the proficiency of PandasAI in analyzing data; now, let’s test it to plot some graphs and see how good it can do in visualizing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a689b0",
   "metadata": {},
   "source": [
    "Let’s create a correlation heatmap of the numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e814732",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Make a heatmap showing the correlation of all the numeric columns in the data\"\n",
    "\n",
    "sdf.chat(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ce4302",
   "metadata": {},
   "source": [
    "That looks great. Under the hood, PandasAI uses Python’s Seaborn and matplotlib libraries to plot data. Let’s create some more graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11738132",
   "metadata": {},
   "source": [
    "First, we ask the system to create a plot of the distribution of BMI using Histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2063bf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Create a histogram of bmi\"\n",
    "\n",
    "sdf.chat(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4455aca2",
   "metadata": {},
   "source": [
    "The distribution of BMI values somewhat resembles the normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29feac52",
   "metadata": {},
   "source": [
    "Then, the distribution of Charges Using Boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb4482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Make a boxplot of charges. Output the median value of charges.\"\n",
    "\n",
    "sdf.chat(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58bdb9d",
   "metadata": {},
   "source": [
    "The median value of the charges column is roughly 9382. In the plot, this is depicted by the line in the middle of the box. It can be clearly seen that the charges column contains many outlier values, which are shown by the circles in the above plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98702a16",
   "metadata": {},
   "source": [
    "Now let’s create some plots showing the relationship between more than one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c46b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Make a stacked horizontal bar chart of region vs smoker. Make the legend smaller. Print just one plot\"\n",
    "sdf.chat(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a377b77b",
   "metadata": {},
   "source": [
    "From the graph, one can easily tell that the southeast region has the greatest number of smokers compared to other regions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2064698",
   "metadata": {},
   "source": [
    "To make things a little more complex, let’s try creating a plot using only a proportion of the data instead of the real data and see how the LLM can perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b784e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Make a scatterplot of bmi with charges and colorcode using the smoker values ('yes' and 'no'). Add legends ('yes' and 'no').\"\n",
    "sdf.chat(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60700344",
   "metadata": {},
   "source": [
    "### Limitations of Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bb695e",
   "metadata": {},
   "source": [
    "From https://geekflare.com/pandasai-analyze-data-natural-language/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaa434b",
   "metadata": {},
   "source": [
    "- <b>API Key Requirement</b>: To use PandasAI, having an API key is essential. If you don’t have sufficient credits in your OpenAI account, you may not be able to use the service.\n",
    "- <b>Processing Time</b>: Sometimes, the service may experience delays in providing results, which can be attributed to high usage or server load. Users should be prepared for potential wait times when querying the service.\n",
    "- <b>Interpretation of Prompts</b>: While you can ask questions via prompts, the system’s ability to explain answers may not be fully developed, and the quality of explanations may vary. This aspect of PandasAI may improve in the future with further development.\n",
    "- <b>Prompt Sensitivity</b>: Users need to be careful when crafting prompts, as even slight changes can lead to different results. This sensitivity to phrasing and prompt structure can impact the consistency of results, especially when working with data plots or more complex queries.\n",
    "- <b>Limitations on Complex Prompts</b>: PandasAI may not handle highly complex prompts or queries as effectively as simpler ones. Users should be mindful of the complexity of their questions and ensure that the tool is suitable for their specific needs.\n",
    "- <b>Inconsistent DataFrame Changes</b>: Users have reported issues with making changes to DataFrames, such as filling null values or dropping null value rows, even when specifying ‘Inplace=True.’ This inconsistency can be frustrating for users trying to modify their data.\n",
    "- <b>Variable Results</b>: When restarting a kernel or re-running prompts, it’s possible to receive different results or interpretations of data from previous runs. This variability can be challenging for users who require consistent and reproducible results. Not applicable to all prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47ad09c",
   "metadata": {},
   "source": [
    "### When not to use PandasAI?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7062b0",
   "metadata": {},
   "source": [
    "From https://blog.enterprisedna.co/pandas-ai/\n",
    "\n",
    "PandasAI is an incredibly powerful tool that can simplify many data analysis tasks, but it’s not always the right tool for the job.\n",
    "\n",
    "- <b>When Working With Sensitive Data</b>: If you’re working with sensitive data, you may not want to use PandasAI, because it sends data to OpenAI’s servers. Even though the library tries to anonymize the data frame by randomizing it, and it offers an option to enforce privacy by not sending the head of the dataframe to the servers, there could still be potential privacy concerns?\n",
    "- <b>When Working With Large Dataframes</b>: PandasAI is not ideal for large dataframes. Because the tool sends a version of your dataframe to the cloud for processing, it could be slow and resource-intensive for large datasets.\n",
    "- <b>When Writing Simple Queries</b>: For simple data manipulations and queries, using PandasAI might be overkill. Regular Pandas operations might be faster and more efficient. For example, if you just want to calculate the mean of a column, using df[‘column’].mean() in Pandas is much more straightforward and faster than setting up a language model and making a request to an external server.\n",
    "- <b>When Learning Data Analysis</b>: If you aim to learn data analysis and Python programming, relying on PandasAI might not be the best approach. While it simplifies many tasks, it also abstracts away the underlying operations, which could impede your understanding of how things work under the hood.\n",
    "- <b>Costs Consideration for PandasAI</b>: OpenAI’s API is not free, and using it extensively could lead to high costs. If you’re working on a project with a tight budget, you might want to stick to traditional data analysis methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2779160f",
   "metadata": {},
   "source": [
    "## Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de59e24d",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2023/07/a-comprehensive-guide-to-pandasai/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
