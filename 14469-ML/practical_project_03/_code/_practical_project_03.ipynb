{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter)\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libs to resize and read files\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "# List all files in the folder\n",
    "#######################################\n",
    "files_x = list(map(str, filter(lambda file: file.is_file(), Path(\"C:/temp/AR_out\").rglob('*'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_resized_list = []\n",
    "file_names_list = []\n",
    "#######################################\n",
    "# resize all files\n",
    "#######################################\n",
    "for file in files_x:\n",
    "    # read image\n",
    "    img = cv2.imread(file, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    # Set Scale\n",
    "    scale_percent = 10 \n",
    "    width = int(img.shape[1] * scale_percent / 100)\n",
    "    height = int(img.shape[0] * scale_percent / 100)\n",
    "    dimension = (width, height)\n",
    "\n",
    "    # resize image\n",
    "    resized = cv2.resize(img, dimension, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    #save an array\n",
    "    image_resized_list.append(resized)\n",
    "    file_names_list.append(file.split('\\\\')[-1].split('.')[0])\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list to a numpy array\n",
    "image_resized_array = np.array(image_resized_list)\n",
    "\n",
    "# Get the number of images and the dimensions of each image\n",
    "num_images, height, width, num_channels = image_resized_array.shape\n",
    "\n",
    "# Reshape the array into a 2D array where each row is a vectorized image\n",
    "data_2d = image_resized_array.reshape(num_images, -1)  # -1 is a placeholder that tells numpy to compute the size of this dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vector = np.mean(data_2d, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Center the data by subtracting the mean\n",
    "centered_data = data_2d - mean_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance_matrix = np.dot(centered_data.T, centered_data) / (num_images - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance_matrix = np.cov(data_2d, rowvar=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # Optional, for better visualization\n",
    "\n",
    "# Display a heatmap of the covariance matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(covariance_matrix, cmap='coolwarm', fmt='.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices that would sort the eigenvalues in descending order\n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "\n",
    "# Sort the eigenvalues and eigenvectors\n",
    "sorted_eigenvalues = eigenvalues[sorted_indices]\n",
    "sorted_eigenvectors = eigenvectors[:, sorted_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_variance = np.sum(sorted_eigenvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_variance = np.cumsum(sorted_eigenvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eigenvectors_to_retain = np.argmax(cumulative_variance / total_variance >= 0.99) + 1\n",
    "print (num_eigenvectors_to_retain)\n",
    "#num_eigenvectors_to_retain = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top eigenvectors to retain 99% of the variance\n",
    "top_eigenvectors = sorted_eigenvectors[:, :num_eigenvectors_to_retain]\n",
    "\n",
    "\n",
    "# Project the centered data onto the selected eigenvectors\n",
    "projected_data = np.dot(centered_data, top_eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project the centered data onto the selected eigenvectors\n",
    "projected_data = np.dot(centered_data, top_eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "#Making a test with a orignal, resized and projected image\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 2034  # Index of the image you want to select\n",
    "source_image = cv2.imread(files_x[index], cv2.IMREAD_UNCHANGED) \n",
    "resized_image = image_resized_array[index]\n",
    "original_image = image_resized_array[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_representation = projected_data[index]\n",
    "reconstructed_image_data = np.dot(projected_representation, top_eigenvectors.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_image = reconstructed_image_data.reshape(height, width, num_channels)\n",
    "reconstructed_image = np.clip(reconstructed_image, 0, 255).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))  # Adjust the figure size to accommodate three images\n",
    "\n",
    "# Display source image\n",
    "plt.subplot(1, 3, 1)  # 1 row, 3 columns, 1st subplot\n",
    "plt.imshow(cv2.cvtColor(source_image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB if necessary\n",
    "plt.title('Source Image')\n",
    "\n",
    "# Display original image\n",
    "plt.subplot(1, 3, 2)  # 1 row, 3 columns, 2nd subplot\n",
    "plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB if necessary\n",
    "#axs[1].imshow(resized_image)\n",
    "plt.title('resized Image')\n",
    "\n",
    "# Display reconstructed image\n",
    "plt.subplot(1, 3, 3)  # 1 row, 3 columns, 3rd subplot\n",
    "plt.imshow(cv2.cvtColor(reconstructed_image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB if necessary\n",
    "plt.title('Vector Image remapped')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merge projected_data with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scr_deep_learning_cnn_keras_py as keras_ml\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting each string by hyphen and storing the results in a new list\n",
    "split_parts = [name.split('-') for name in file_names_list]\n",
    "\n",
    "# Creating a DataFrame from the list of split parts\n",
    "df02 = pd.DataFrame(split_parts, columns=['gender', 'seq', 'type'])\n",
    "\n",
    "print(df02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_df = pd.DataFrame(projected_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([projected_df, df02], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[['Variance', 'Skewness', 'Curtosis', 'Entropy']]\n",
    "y = df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset (CIFAR-10)\n",
    "(X_train, y_train), (X_test, y_test) = keras_ml.cifar10.load_data()\n",
    "\n",
    "print('Learning set:')\n",
    "print('X: ', end='')\n",
    "print(X_train.shape)\n",
    "print('y: ', end='')\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Test set:')\n",
    "print('X: ', end='')\n",
    "print(X_test.shape)\n",
    "print('y: ', end='')\n",
    "print(y_test.shape)\n",
    "\n",
    "# DEBUG. Plot some of the images\n",
    "plt.figure(figsize=(18, 9))\n",
    "\n",
    "num_rows = 4\n",
    "num_cols = 5\n",
    "\n",
    "# plot each of the images in the batch and the associated ground truth labels.\n",
    "for i in range(num_rows*num_cols):\n",
    "    ax = plt.subplot(num_rows, num_cols, i + 1)\n",
    "    plt.imshow(X_train[i,:,:])\n",
    "    ax.title.set_text(y_train[i,0])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "# Normalize images to the range [0, 1].\n",
    "X_train = X_train.astype(\"float32\") / 255\n",
    "X_test  = X_test.astype(\"float32\") / 255\n",
    "\n",
    "# Change the labels from integer to categorical data.\n",
    "print('Original (integer) label for the first training sample: ', y_train[0])\n",
    "\n",
    "# Convert labels to one-hot encoding.\n",
    "y_train = keras_ml.to_categorical(y_train)\n",
    "y_test  = keras_ml.to_categorical(y_test)\n",
    "\n",
    "print('After conversion to categorical one-hot encoded labels: ', y_train[0])\n",
    "\n",
    "# Create the model.\n",
    "model = keras_ml.cnn_model()\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "             )\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=.3,\n",
    "                   )\n",
    "\n",
    "\n",
    "# Retrieve training results.\n",
    "train_loss = history.history[\"loss\"]\n",
    "train_acc  = history.history[\"accuracy\"]\n",
    "valid_loss = history.history[\"val_loss\"]\n",
    "valid_acc  = history.history[\"val_accuracy\"]\n",
    "\n",
    "keras_ml.plot_results([ train_loss, valid_loss ],\n",
    "            ylabel=\"Loss\",\n",
    "            ylim = [0.0, 5.0],\n",
    "            metric_name=[\"Training Loss\", \"Validation Loss\"],\n",
    "            color=[\"g\", \"b\"]);\n",
    "\n",
    "keras_ml.plot_results([ train_acc, valid_acc ],\n",
    "            ylabel=\"Accuracy\",\n",
    "            ylim = [0.0, 1.0],\n",
    "            metric_name=[\"Training Accuracy\", \"Validation Accuracy\"],\n",
    "            color=[\"g\", \"b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset (CIFAR-10)\n",
    "(X_train, y_train), (X_test, y_test) = keras_ml.cifar10.load_data()\n",
    "\n",
    "print('Learning set:')\n",
    "print('X: ', end='')\n",
    "print(X_train.shape)\n",
    "print('y: ', end='')\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Test set:')\n",
    "print('X: ', end='')\n",
    "print(X_test.shape)\n",
    "print('y: ', end='')\n",
    "print(y_test.shape)\n",
    "\n",
    "# DEBUG. Plot some of the images\n",
    "plt.figure(figsize=(18, 9))\n",
    "\n",
    "num_rows = 4\n",
    "num_cols = 5\n",
    "\n",
    "# plot each of the images in the batch and the associated ground truth labels.\n",
    "for i in range(num_rows*num_cols):\n",
    "    ax = plt.subplot(num_rows, num_cols, i + 1)\n",
    "    plt.imshow(X_train[i,:,:])\n",
    "    ax.title.set_text(y_train[i,0])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "# Normalize images to the range [0, 1].\n",
    "X_train = X_train.astype(\"float32\") / 255\n",
    "X_test  = X_test.astype(\"float32\") / 255\n",
    "\n",
    "# Change the labels from integer to categorical data.\n",
    "print('Original (integer) label for the first training sample: ', y_train[0])\n",
    "\n",
    "# Convert labels to one-hot encoding.\n",
    "y_train = keras_ml.to_categorical(y_train)\n",
    "y_test  = keras_ml.to_categorical(y_test)\n",
    "\n",
    "print('After conversion to categorical one-hot encoded labels: ', y_train[0])\n",
    "\n",
    "# Create the model.\n",
    "model = keras_ml.cnn_model()\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "             )\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=.3,\n",
    "                   )\n",
    "\n",
    "\n",
    "# Retrieve training results.\n",
    "train_loss = history.history[\"loss\"]\n",
    "train_acc  = history.history[\"accuracy\"]\n",
    "valid_loss = history.history[\"val_loss\"]\n",
    "valid_acc  = history.history[\"val_accuracy\"]\n",
    "\n",
    "keras_ml.plot_results([ train_loss, valid_loss ],\n",
    "            ylabel=\"Loss\",\n",
    "            ylim = [0.0, 5.0],\n",
    "            metric_name=[\"Training Loss\", \"Validation Loss\"],\n",
    "            color=[\"g\", \"b\"]);\n",
    "\n",
    "keras_ml.plot_results([ train_acc, valid_acc ],\n",
    "            ylabel=\"Accuracy\",\n",
    "            ylim = [0.0, 1.0],\n",
    "            metric_name=[\"Training Accuracy\", \"Validation Accuracy\"],\n",
    "            color=[\"g\", \"b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a Gender model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a Glasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a ID model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a Facial expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
