{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"Tamplaged                                                                              \">\n",
    "<b><center><font size=\"4\">Practical Project 3</font></center></b>\n",
    "<b><center><font size=\"3\">Convolutional Neural Networks</font></center></b>\n",
    "<b><center><font size=\"2\">Predict Image</font></center></b>\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook Developed by**: [Rene Jerez](https://github.com/renejerez)<br>\n",
    "**email:**  rene.jerez@ubi.pt<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Classsification MNIST<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\">\n",
    "  <ul class=\"toc-item\">\n",
    "    <li><span><a href=\"#Setup-and-Load-Data\" data-toc-modified-id=\"Setup-and-Load-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup and Load Data</a></span>\n",
    "      <div class=\"toc\">\n",
    "        <ul class=\"toc-item\">\n",
    "    <li><span><a href=\"#Install-Libraries\" data-toc-modified-id=\"Install-Libraries-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Install Libraries</a></span>\n",
    "    </li>\n",
    "    <li><span><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Import Libraries</a></span>\n",
    "    </li>\n",
    "    <li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Load Data</a></span>\n",
    "    </li>\n",
    "    <li><span><a href=\"#Transformed-Data\" data-toc-modified-id=\"Transformed-Data-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Transformed Data</a></span>\n",
    "    </li>\n",
    "        </ul>\n",
    "      </div>\n",
    "    </li>\n",
    "    <li><span><a href=\"Implement-a-classification-model\" data-toc-modified-id=\"Implement-a-classification-model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Implement a classification model</a></span>\n",
    "      <div class=\"toc\">\n",
    "        <ul class=\"toc-item\">\n",
    "    <li><span><a href=\"#Architecture-based-on-the-doc-from-Tutorial/Resource\" data-toc-modified-id=\"Architecture-based-on-the-doc-from-Tutorial/Resource-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Architecture based on the doc from Tutorial/Resource</a></span>\n",
    "      <div class=\"toc\">\n",
    "        <ul class=\"toc-item\">\n",
    "    <li><span><a href=\"#Architecture-based-on-the-doc-from-Tutorial/Resource\" data-toc-modified-id=\"Architecture-based-on-the-doc-from-Tutorial/Resource-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Architecture based on the doc from Tutorial/Resource</a></span>\n",
    "    </li>\n",
    "    <li><span><a href=\"#Architecture-based-on-the-topology-recommended\" data-toc-modified-id=\"Architecture-based-on-the-topology-recommended-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Architecture based on the topology recommended</a></span>\n",
    "    </li>\n",
    "    <li><span><a href=\"#Architecture-based-on-function-activate-LeakyReLU\" data-toc-modified-id=\"Architecture-based-on-function-activate-LeakyReLU-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Architecture based on function activate LeakyReLU</a></span>\n",
    "    </li>\n",
    "        </ul>\n",
    "      </div>\n",
    "    </li>\n",
    "    <li><span><a href=\"#Train-Networks\" data-toc-modified-id=\"Train-Networks-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Train Networks</a></span>\n",
    "    </li>\n",
    "        </ul>\n",
    "      </div>\n",
    "    </li>\n",
    "    <li><span><a href=\"#Results\" data-toc-modified-id=\"Results-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Results</a></span>\n",
    "      <div class=\"toc\">\n",
    "        <ul class=\"toc-item\">\n",
    "    <li><span><a href=\"#Table-to-compare-the-6-models\" data-toc-modified-id=\"Table-to-compare-the-6-models-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Table to compare the 6 models</a></span>\n",
    "    </li>\n",
    "    <li><span><a href=\"#Chart-to-see-the-6-model-with-Train-and-Test-data\" data-toc-modified-id=\"Chart-to-see-the-6-model-with-Train-and-Test-data-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Chart to see the 6 model with Train and Test data</a></span>\n",
    "    </li>\n",
    "        </ul>\n",
    "      </div>\n",
    "    </li>\n",
    "  </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# Contains Solutions and Notes based on Machine Learning Specialization by Andrew NG\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install torch\n",
    "#!pip install torch torchvision\n",
    "#!pip uninstall torch torchvision\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# Import Libraries to start work\n",
    "##########################################################\n",
    "import gc\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.linalg import eigh\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Resize by Hugo ProenÃ§a script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = r'C:\\Users\\rene_\\Downloads\\ML\\week07\\AR'\n",
    "output_folder = r'C:\\Users\\rene_\\Downloads\\ML\\week07\\AR_out'\n",
    "\n",
    "if os.path.isdir(output_folder):\n",
    "    shutil.rmtree(output_folder)\n",
    "\n",
    "os.mkdir(output_folder)\n",
    "\n",
    "files = os.listdir(input_folder)\n",
    "\n",
    "proportion = 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################################################################################################\n",
    "#   STEP 1\n",
    "#   Loading data and concatenate everything into a big matrix\n",
    "################################################################################################\n",
    "\n",
    "dataset = []\n",
    "new_size = []\n",
    "\n",
    "# Initialize a counter to track iterations\n",
    "file_count = 0\n",
    "total_files = sum(1 for f in files if f.find('.jpg') != -1)  # Count total valid '.jpg' files\n",
    "\n",
    "for f in files:\n",
    "    if f.find('.jpg') == -1:\n",
    "        continue\n",
    "\n",
    "    # Print the first file\n",
    "    if file_count == 0:\n",
    "        print(f\"First file: {f}\")\n",
    "    \n",
    "    # Process the image\n",
    "    img = cv2.imread(os.path.join(input_folder, f))\n",
    "    img = cv2.resize(img, None, fx=proportion, fy=proportion)\n",
    "    new_size = img.shape\n",
    "    dataset.append(img.flatten())\n",
    "\n",
    "    # Print the last file\n",
    "    if file_count == total_files - 1:\n",
    "        print(f\"Last file: {f}\")\n",
    "\n",
    "    file_count += 1\n",
    "\n",
    "dataset = np.asarray(dataset)\n",
    "df = pd.DataFrame(dataset)\n",
    "df.to_csv('df.csv', index=False)\n",
    "\n",
    "print('Dataset created: %d rows x %d columns' % (dataset.shape[0], dataset.shape[1]))\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#   STEP 2\n",
    "#   Obtain mu, covariance matrix and eigen values/vectors.\n",
    "################################################################################################\n",
    "\n",
    "mu = np.mean(dataset, axis=0)\n",
    "\n",
    "covar = np.cov(dataset.T)       #the \"cov\" function in numpy requires each instance in a different column\n",
    "\n",
    "eig_values, eig_vectors = eigh(covar)\n",
    "\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#   STEP 3\n",
    "#   Find the number of eigenvectors required to keep 99% of the information\n",
    "################################################################################################\n",
    "\n",
    "amount_information = 0.99\n",
    "\n",
    "keep_inf = np.cumsum(np.flip(eig_values)) / np.sum(eig_values)  #This \"eig\" implementation returns the eigenvalues/eigenvectors\n",
    "                                                                # in increasing order\n",
    "\n",
    "pos = np.where(keep_inf >= amount_information)[0][0]\n",
    "\n",
    "M = np.fliplr(eig_vectors[:, -pos:])                            #Select the top eigenvectors\n",
    "\n",
    "################################################################################################\n",
    "#   STEP 4\n",
    "#   Write everything in file\n",
    "################################################################################################\n",
    "\n",
    "with open(os.path.join(output_folder, 'data.dat'), 'wb') as file:\n",
    "    # Serialize and write the variable to the file\n",
    "    pickle.dump([mu, covar, eig_vectors, eig_values, M, keep_inf], file)\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#   STEP 5\n",
    "#   Write top-k eigenvectors\n",
    "################################################################################################\n",
    "\n",
    "k = 10\n",
    "for i in range(k):\n",
    "    img = np.reshape(M[:, i], new_size)\n",
    "    img = ((cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX,\n",
    "                                dtype=cv2.CV_32F)) * 255).astype(np.uint8)\n",
    "\n",
    "    img = cv2.resize(img, None, fx=1.0/proportion, fy=1.0/proportion)\n",
    "    cv2.imwrite(os.path.join(output_folder, 'eigenvector_%d.png' % i), img)\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#   STEP 6\n",
    "#   Project images into PCA space and remap them into the original space\n",
    "################################################################################################\n",
    "\n",
    "for i, elt in enumerate(dataset):\n",
    "\n",
    "    #project\n",
    "    projected = np.matmul(elt - mu, M)\n",
    "\n",
    "    #remap\n",
    "    remapped = np.clip(np.matmul(projected, M.T) + mu, 0, 255)\n",
    "\n",
    "    img = np.reshape(remapped, new_size)\n",
    "    img = cv2.resize(img, None, fx=1.0 / proportion, fy=1.0 / proportion)\n",
    "    cv2.imwrite(os.path.join(output_folder, files[i]), img)             # To perceive how much information is kept/lost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "#   Validation process with multiple indices\n",
    "################################################################################################\n",
    "\n",
    "# Set a list of valid indices within the range of files\n",
    "validation_indices = [3314, 1800]  # Example indices for validation\n",
    "\n",
    "# Loop through each index in the validation list\n",
    "for validation_index in validation_indices:\n",
    "    print(f\"\\nValidating index: {validation_index}\")\n",
    "\n",
    "    # Load the original image directly\n",
    "    original_image_path = os.path.join(input_folder, files[validation_index])\n",
    "    original_image = cv2.imread(original_image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Check if the original image exists\n",
    "    if original_image is None:\n",
    "        print(f\"Error: Original image not found or could not be loaded at index {validation_index}\")\n",
    "        continue  # Skip to the next index\n",
    "\n",
    "    # Resized image (already in memory as part of the dataset)\n",
    "    resized_image = np.reshape(dataset[validation_index], new_size).astype(np.uint8)\n",
    "\n",
    "    # Projected image path\n",
    "    projected_image_path = os.path.join(output_folder, files[validation_index])\n",
    "\n",
    "    # Check if the projected image file exists\n",
    "    if not os.path.exists(projected_image_path):\n",
    "        print(f\"Error: Projected image file not found at {projected_image_path}\")\n",
    "        continue  # Skip to the next index\n",
    "\n",
    "    # Load the projected image\n",
    "    projected_image = cv2.imread(projected_image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Validate that the projected image was loaded correctly\n",
    "    if projected_image is None:\n",
    "        print(f\"Error: Projected image could not be loaded at {projected_image_path}\")\n",
    "        continue  # Skip to the next index\n",
    "\n",
    "    # Convert BGR to RGB for matplotlib compatibility\n",
    "    original_image_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    resized_image_rgb = resized_image  # Already compatible\n",
    "    projected_image_rgb = cv2.cvtColor(projected_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Plot the images side by side\n",
    "    plt.figure(figsize=(18, 9))\n",
    "\n",
    "    # Original image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(original_image_rgb)\n",
    "    plt.title(f\"Original Image - Index {validation_index}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Resized image\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(resized_image_rgb)\n",
    "    plt.title(\"Resized Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Projected image\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(projected_image_rgb)\n",
    "    plt.title(\"Projected Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### targets dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['filename'] = files\n",
    "df['gender'] = df['filename'].apply(lambda x: x.split('-')[0])  # Extract gender\n",
    "df['id'] = df['filename'].apply(lambda x: x.split('-')[1])      # Extract ID\n",
    "df['category'] = df['filename'].apply(lambda x: x.split('-')[2].split('.')[0])  # Extract category\n",
    "df = df.drop(columns=['filename'], errors='ignore')\n",
    "df.to_csv('df_target.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gender = pd.read_csv('df_target.csv', nrows=3000)\n",
    "df_gender = df_gender.drop(columns=['filename', 'id', 'category'], errors='ignore')\n",
    "print(df_gender['gender'].unique())  # Display unique values\n",
    "df_gender['gender'] = df_gender['gender'].astype('category').cat.codes\n",
    "print(df_gender['gender'].unique())  # Display unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.image import resize\n",
    "\n",
    "# Assuming `df` contains images flattened to 3306 columns and a label column\n",
    "image_size = (57, 58)  # Original dimensions of the images\n",
    "num_classes = 2  # Adjust to the number of classes in your dataset\n",
    "\n",
    "# Separate features and labels\n",
    "X = df_gender.iloc[:, :-1].values  # Assuming last column is the label\n",
    "y = df_gender.iloc[:, -1].values  # Adjust as necessary for your dataset\n",
    "\n",
    "# Reshape and preprocess the image data\n",
    "X = X.reshape(-1, image_size[0], image_size[1], 1)  # Grayscale images (1 channel)\n",
    "X_resized = resize(X, [224, 224])  # Resize to 224x224\n",
    "X_rgb = np.repeat(X_resized, 3, axis=-1)  # Convert grayscale to RGB\n",
    "X_rgb = X_rgb / 255.0  # Normalize the data\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y = to_categorical(y, num_classes)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_rgb, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load a pre-trained ResNet50 model with ImageNet weights\n",
    "base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=10, \n",
    "                    batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract loss and accuracy\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_loss, 'b', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_acc, 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.DataFrame(dataset)\n",
    "df_model['filename'] = files  # Add the list of file names to the existing DataFrame\n",
    "df_model['gender'] = df_model['filename'].str.split('-').str[0]\n",
    "df_model['gender'] = df_model['gender'].astype('category').cat.codes\n",
    "df_model = df_model.drop(columns=['filename'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess and predict for a single row\n",
    "def predict_single_row(model, row, image_size=(57, 58), channels=1):\n",
    "    # Extract features and reshape\n",
    "    features = row[:-1].reshape(1, image_size[0], image_size[1], channels)\n",
    "    # Normalize the data\n",
    "    features = features / 255.0\n",
    "    # Predict using the model\n",
    "    prediction = model.predict(features)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    return predicted_class, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of indices to test till 3314 rows\n",
    "test_indices = [1800, 3314]\n",
    "\n",
    "# Loop through the selected indices\n",
    "for index in test_indices:\n",
    "    test_row = df_model.iloc[index].values  # Get the row by index\n",
    "    \n",
    "    # Extract the actual class (right class) from the last column\n",
    "    actual_class = test_row[-1]\n",
    "\n",
    "    # Predict on the test row\n",
    "    predicted_class, probabilities = predict_single_row(model, test_row)\n",
    "\n",
    "    # Format probabilities with class labels\n",
    "    class_probabilities = {f\"Class {i}\": round(prob, 4) for i, prob in enumerate(probabilities[0])}\n",
    "\n",
    "    # Display comparison\n",
    "    print(f\"Row Index: {index}\")\n",
    "    print(f\"Actual Class: {actual_class}\")\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n",
    "    print(f\"Class Probabilities: {class_probabilities}\")\n",
    "    print(\"-\" * 50)  # Separator for readability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
