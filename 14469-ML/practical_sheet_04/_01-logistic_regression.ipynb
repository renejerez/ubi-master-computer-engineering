{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Practical sheet 4 (Experimental Setup)"]},{"cell_type":"markdown","metadata":{},"source":["#### 00-Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["##########################################################\n","# Import Libraries to start work\n","##########################################################\n","import pandas as pd\n","import numpy as np\n","import sklearn as sk\n","import matplotlib.pyplot as plt\n","from datetime import datetime, timedelta\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import confusion_matrix"]},{"cell_type":"markdown","metadata":{},"source":["#### 01-Data & Transformation"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Variance</th>\n","      <th>Skewness</th>\n","      <th>Curtosis</th>\n","      <th>Entropy</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3.62160</td>\n","      <td>8.6661</td>\n","      <td>-2.8073</td>\n","      <td>-0.44699</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.54590</td>\n","      <td>8.1674</td>\n","      <td>-2.4586</td>\n","      <td>-1.46210</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3.86600</td>\n","      <td>-2.6383</td>\n","      <td>1.9242</td>\n","      <td>0.10645</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3.45660</td>\n","      <td>9.5228</td>\n","      <td>-4.0112</td>\n","      <td>-3.59440</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.32924</td>\n","      <td>-4.4552</td>\n","      <td>4.5718</td>\n","      <td>-0.98880</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Variance  Skewness  Curtosis  Entropy  Class\n","0   3.62160    8.6661   -2.8073 -0.44699      0\n","1   4.54590    8.1674   -2.4586 -1.46210      0\n","2   3.86600   -2.6383    1.9242  0.10645      0\n","3   3.45660    9.5228   -4.0112 -3.59440      0\n","4   0.32924   -4.4552    4.5718 -0.98880      0"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(\"banknote.csv\",names=[\"Variance\",\"Skewness\",\"Curtosis\",\"Entropy\",\"Class\"])\n","df.head()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["X = df[['Variance', 'Skewness', 'Curtosis', 'Entropy']].values\n","y = df['Class'].values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","#########################################################################\n","#   Read, Normalize and Split Data\n","#########################################################################\n","\n","\n","with open('banknote.csv') as csv_file:\n","    csv_reader = csv.reader(csv_file, delimiter=',')\n","    next(csv_reader) # to skip the header file\n","    X = []\n","    y = []\n","    for row in csv_reader:\n","        y.append(int(float(row[0]) == 1))\n","        temp= [float(i) for i in row[1:]]\n","        X.append(temp)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["\n","X = np.asarray(X)\n","y = np.asarray(y)\n","\n","scaler = MinMaxScaler()\n","scaler.fit(X)\n","X = scaler.transform(X)\n","X = np.append(X, np.ones((X.shape[0],1), np.float64), axis=1)\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.76900389 0.83964273 0.10678269 0.73662766 1.        ]\n"," [0.83565902 0.82098209 0.12180412 0.64432563 1.        ]\n"," [0.78662859 0.41664827 0.31060805 0.78695091 1.        ]\n"," ...\n"," [0.23738543 0.01176814 0.98560321 0.52475518 1.        ]\n"," [0.25084193 0.20170105 0.76158701 0.6606745  1.        ]\n"," [0.32452819 0.49074676 0.34334762 0.88594888 1.        ]]\n"]}],"source":["print(X)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=1234)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["#########################################################################\n","#   Logistic regression\n","#########################################################################\n","## incluir os pesos somatorio dos pesos ao quadrado\n","\n","def compute_loss(y_true, y_pred):\n","    # binary cross entropy\n","    epsilon = 1e-9\n","    y1 = y_true * np.log(y_pred + epsilon)\n","    y2 = (1-y_true) * np.log(1 - y_pred + epsilon)\n","    return -np.mean(y1 + y2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def _sigmoid(x):\n","    return 1 / (1 + np.exp(-x))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def feed_forward(X, weights, bias):\n","    z = np.dot(X, weights) + bias\n","    A = _sigmoid(z)\n","    return A"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def fit(X, y, n_iters, lr):\n","    n_samples, n_features = X.shape\n","\n","    # init parameters\n","    weights = np.zeros(n_features)\n","    bias = 0\n","    losses = []\n","\n","    # gradient descent\n","    for _ in range(n_iters):\n","        A = feed_forward(X, weights, bias)\n","        losses.append(compute_loss(y,A))\n","        dz = A - y # derivative of sigmoid and bce X.T*(A-y)\n","        # compute gradients\n","        dw = (1 / n_samples) * np.dot(X.T, dz)\n","        db = (1 / n_samples) * np.sum(dz)\n","        # update parameters\n","        weights -= lr * dw\n","        bias -= lr * db\n","      \n","    return weights, bias, losses"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def predict(X, weights, bias):\n","    threshold = .5\n","    y_hat = np.dot(X, weights) + bias\n","    y_predicted = _sigmoid(y_hat)\n","    y_predicted_cls = [1 if i > threshold else 0 for i in y_predicted]\n","    return np.array(y_predicted_cls)"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[],"source":["learning_rate = 0.1\n","n_iters = 1000\n","alpha = 10000"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[],"source":["\n","weights, bias, losses = fit(X_train, y_train, n_iters, learning_rate,alpha)"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Test accuracy: 0.582\n"]}],"source":["\n","predictions = predict(X_test, weights, bias)\n","print(\"Test accuracy: {0:.3f}\".format(np.sum(np.diag(cm))/np.sum(cm)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","plt.ion()\n","plt.figure(1)\n","plt.plot(range(n_iters), losses, '-g', label='Tensorflow')\n","plt.xlabel('Iterations')\n","plt.ylabel('Loss')\n","plt.legend(loc='upper right')\n","plt.grid()\n","plt.show()\n","plt.pause(0.01)"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Confusion Matrix:\n","[[160   0]\n"," [115   0]]\n"]}],"source":["\n","cm  = confusion_matrix(np.asarray(y_test), np.asarray(predictions))\n","print(\"Confusion Matrix:\")\n","print(np.array(cm))\n"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":2}
